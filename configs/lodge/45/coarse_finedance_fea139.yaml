NAME: FineDance_Coarse_relative_noNorm_128len_139_diff_bc800 # Experiment name
ACCELERATOR: 'gpu' # Devices optioncal: “cpu”, “gpu”, “tpu”, “ipu”, “hpu”, “mps, “auto”
DEVICE: [1]   #,  #  # Index of gpus eg. [0] or [0,1,2,3]

# FOLDER: ./experiments
SEED_VALUE: 1234
Norm: True
DEBUG: False
Discriminator: False
FineTune: False
TRAIN:
  STAGE: diffusion    # diffusion
  SPLIT: 'train'
  NUM_WORKERS: 16 # Number of workers
  BATCH_SIZE: 800 # Size of batches
  START_EPOCH: 1 # Start epoch
  END_EPOCH: 3001 # End epoch
  RESUME: '' # Experiment path to be resumed training
  PRETRAINED_VAE: ''
  PRETRAINED: '' # Pretrained model path
  DATASETS: ['FINEDANCE_139CUT'] # Training datasets

  # OPTIM:
  #   TYPE: 'AdamW' # Optimizer type
  #   LR: 1e-4 # Learning rate
  OPTIM:
    TYPE: 'Adan' # Optimizer type
    LR: 4e-4 # Learning rate

  ABLATION:
    VAE_TYPE: 'no' # vae ablation: actor or mcross
    VAE_ARCH: 'encoder_decoder' # mdiffusion vae architecture
    PE_TYPE: 'actor' # mdiffusion mld or actor
    DIFF_PE_TYPE: 'actor' # mdiffusion mld or actor
    SKIP_CONNECT: False # skip connection for denoiser va
    # use linear to expand mean and std rather expand token nums
    MLP_DIST: False
    IS_DIST: False # Mcross distribution kl
    PREDICT_EPSILON: False # noise or motion

EVAL:
  SPLIT: 'gtest'
  BATCH_SIZE: 256 # Evaluating Batch size
  NUM_WORKERS: 16 # Evaluating Batch size

TEST:
  TEST_DIR: ''
  CHECKPOINTS: ''
  SPLIT: 'gtest'
  BATCH_SIZE: 256 # Testing Batch size
  NUM_WORKERS: 12 # Evaluating Batch size
  SAVE_PREDICTIONS: True # Weather to save predictions
  COUNT_TIME: False # Weather to count time during test
  REPLICATION_TIMES: 2 # Number of times to replicate the test
  MM_NUM_SAMPLES: 100 # Number of samples for multimodal test
  MM_NUM_REPEATS: 30 # Number of repeats for multimodal test
  MM_NUM_TIMES: 10 # Number of times to repeat the multimodal test
  DIVERSITY_TIMES: 300 # Number of times to repeat the diversity test
  REP_I: 0
  DATASETS: ['FINEDANCE_139CUT']

model:
  target: 'modules'
  vae_type: 'no'
  
  vae: true # whether vae model
  model_type: Global_Module # model type
  condition: 'music'
  latent_dim: [1, 256]  #[512, 135]    # [${FINEDANCE.full_seq_len}, ${DATASET.NFEATS}]      #  # latent dimension
  ff_size: 1024 #
  num_layers: 9 # number of layers
  num_head: 4 # number of head layers
  droupout: 0.1 # dropout rate
  activation: gelu # activation type
  guidance_scale: 7.5   # 7.5 #
  guidance_uncondp: 0.1 # 0.1 0.25

  # denoiser:
  #   target: dld.models.architectures.dld_denoiser.DldDenoiser
  #   params:
  #     music_encoded_dim: ${model.DanceDecoder.cond_feature_dim}
  #     ff_size: 1024
  #     num_layers: 9
  #     num_heads: 4
  #     dropout: 0.1
  #     normalize_before: False
  #     activation: 'gelu'
  #     flip_sin_to_cos: True
  #     return_intermediate_dec: False
  #     position_embedding: 'learned'
  #     arch: trans_enc
  #     freq_shift: 0
  #     condition: ${model.condition}
  #     latent_dim: ${model.latent_dim}
  #     guidance_scale: ${model.guidance_scale}
  #     guidance_uncondp: ${model.guidance_uncondp}
  #     nfeats: ${DATASET.NFEATS}
  #     ablation: ${TRAIN.ABLATION}

  diffusion:   
    target: dld.models.architectures.diffusion.GaussianDiffusion
    params:
      horizon: ${FINEDANCE.full_seq_len}
      repr_dim: ${FINEDANCE.nfeats}
      schedule: "cosine"
      n_timestep: 1000
      predict_epsilon: False
      loss_type: "l2"
      use_p2: False
      cond_drop_prob: 0.25
      guidance_weight: 2
 
  DanceDecoder:   
    target: dld.models.architectures.model.DanceDecoder
    params:
      nfeats: ${FINEDANCE.nfeats}
      seq_len: ${FINEDANCE.full_seq_len}
      latent_dim: 512
      ff_size: 1024
      num_layers: 8
      num_heads: 8
      dropout: 0.1
      cond_feature_dim: 35
      activation: gelu
        

LOSS:
  TYPE: smpl_loss # Losses type
  LAMBDA_MSE: 0.636 
  LAMBDA_V: 2.964 
  LAMBDA_FK: 0.636
  LAMBDA_FOOT: 10.942 # Lambda for reconstruction losses
  DIST_SYNC_ON_STEP: True # Sync Losses on step when distributed trained
METRIC:
  FORCE_IN_METER: True
  DIST_SYNC_ON_STEP: True  # # Sync Losses on step when distributed trained
  TYPE: ['DanceDiffuse_Metric']  # DanceAE_Metric
LOGGER:
  SACE_CHECKPOINT_EPOCH: 100      # 保存间隔
  LOG_EVERY_STEPS: 50
  VAL_EVERY_STEPS: 50
  TENSORBOARD: true
  WANDB:
    OFFLINE: false
    PROJECT: null
    RESUME_ID: null
RENDER:
  JOINT_TYPE: mmm
  INPUT_MODE: npy
  DIR: ''
  NPY: ''
  DENOISING: true
  OLDRENDER: true
  RES: high
  DOWNSAMPLE: true
  FPS: 12.5
  CANONICALIZE: true
  EXACT_FRAME: 0.5
  NUM: 7
  MODE: sequence
  VID_EXT: mp4
  ALWAYS_ON_FLOOR: false
  GT: false
DEMO:
  MusicDir: /data2/lrh/dataset/fine_dance/origin/music
  RENDER: false
  EXAMPLE: null
  use_cached_features: false

FINEDANCE:
  mix: False           # 是否做混合的数据增强
  full_seq_len: 256   # 150
  length_fi: 128
  windows: 10  # 16   #40   #
  is_mirror: False    # 是否做镜像的数据增强
  nfeats: 139
  njoints: 22   
  mode: single  # "single" , "double_react", "double"
  partial: full   # "full" , "morden", "tradition"
  GENRE_NUM: 16
